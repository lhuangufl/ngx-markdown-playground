The Hypothetical Portfolio Exercise (HPE) is a component of the Fundamental Review of the Trading Book (FRTB). 
It involves the hypothetical revaluation of a bank's trading book to assess the impact of market risk factors on the value of the portfolio. The results of the HPE are used to determine the market risk capital charge (MRCC) that the bank must hold to cover potential losses in the trading book.


import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.types.DataTypes;
import org.apache.spark.sql.types.StructField;
import org.apache.spark.sql.types.StructType;
import java.util.Map;

public class SparkDataProcessor {

    /**
     * Processes the given datasets.
     *
     * @param sparkSession The Spark session to use.
     * @param dsMap A map of dataset names to datasets.
     * @return A processed dataset.
     */
    public Dataset<Row> process(SparkSession sparkSession, Map<String, Dataset<Row>> dsMap) {
        Dataset<Row> inputDataset = dsMap.get("inputDatasetName");
        if (inputDataset != null) {
            // Creating a new column 'mysensitivity' which is 'sensitivity' + 1
            return inputDataset.withColumn(
                "mysensitivity",
                functions.col("sensitivity").plus(1)
            );
        } else {
            // Create a DataFrame schema with a 'mysensitivity' column
            StructType schema = new StructType(new StructField[]{
                DataTypes.createStructField("mysensitivity", DataTypes.DoubleType, true)
            });

            // Create an empty DataFrame with the defined schema
            return sparkSession.createDataFrame(sparkSession.emptyRDD(), schema);
        }
    }
}


import org.apache.commons.math3.optim.linear.LinearObjectiveFunction;
import org.apache.commons.math3.optim.linear.LinearConstraint;
import org.apache.commons.math3.optim.linear.Relationship;
import org.apache.commons.math3.optim.linear.SimplexSolver;
import org.apache.commons.math3.optim.linear.PointValuePair;
import org.apache.commons.math3.optim.nonlinear.scalar.GoalType;
import org.apache.commons.math3.optim.linear.NonNegativeConstraint;

public class HedgeAllocationSolver {

    public static void main(String[] args) {
        // Define the hedge sensitivity array and ideal allocation ratio
        double[] hedgeSensitivityArray = {10, 20};

        // Calculate the total aggregate hedge sensitivity by summing the elements of the array
        double totalAggregateHedgesSensitivity = 0;
        for (double sensitivity : hedgeSensitivityArray) {
            totalAggregateHedgesSensitivity += sensitivity;
        }


During our recent evaluations, an important issue surfaced regarding the attribute mapping in our Data Dictionary. It appears that our system maps attributes based on their order rather than their names. This was initially thought to be a minor quirk; however, it has potential to introduce subtle and hard-to-detect errors in our data handling processes.

Issue Description:
When extracting data sets from our primary source, Zinc, we expect each attribute to correspond precisely with our internal data dictionary. However, due to the attribute mapping being order-dependent rather than name-dependent, discrepancies can occur if the order in Zinc changes or if attributes are interpreted differently due to their sequence.

This issue was highlighted during the tests involving our new Data Quality Control module, which could amplify the risk of data mismatches and inconsistencies.

Proposed Next Steps:

Immediate Review: I recommend that we conduct an immediate review of how attributes are mapped in our system, particularly focusing on modules interfacing with external data sources like Zinc.
Risk Assessment: We need to evaluate the potential impacts this could have on our data integrity, especially in critical data flows.
Update Implementation: Depending on our findings, it may be necessary to update our system to map attributes based on names instead of order to prevent any future issues.
Testing and Validation: After implementing changes, a thorough testing phase should follow to ensure that the data is accurately mapped and consistent with our data dictionary standards.
Please let me know your thoughts on this and how soon we can assemble the team to discuss this in further detail. Your immediate attention to this matter would be greatly appreciated as we strive to maintain the highest standards of data quality and integrity.
        double idealHedgeAllocationRatioForSA = 0.75; // This would be ratioConstant

        // The objective function coefficients (in the Python code, this is hedgeSensitivityArray - idealHedgeAllocationRatioForSA * totalAggregateHedgesSensitivity)
        double[] objectiveCoefficients = new double[hedgeSensitivityArray.length];
        for (int i = 0; i < hedgeSensitivityArray.length; i++) {
            objectiveCoefficients[i] = hedgeSensitivityArray[i] - idealHedgeAllocationRatioForSA * totalAggregateHedgesSensitivity;
        }

        // Create the linear objective function to minimize
        LinearObjectiveFunction objectiveFunction = new LinearObjectiveFunction(objectiveCoefficients, 0);

        // Define the constraints (in this case, we are not enforcing boolean constraints)
        Collection<LinearConstraint> constraints = new ArrayList<LinearConstraint>();
        for (int i = 0; i < hedgeSensitivityArray.length; i++) {
            // Each hedge sensitivity must be non-negative
            constraints.add(new LinearConstraint(new double[hedgeSensitivityArray.length], Relationship.GEQ, 0));
        }

        // Create and run the solver
        SimplexSolver solver = new SimplexSolver();
        PointValuePair solution = solver.optimize(
                new MaxIter(100), // Maximum number of iterations
                objectiveFunction, // Objective function to minimize
                new LinearConstraintSet(constraints), // The constraints
                GoalType.MINIMIZE, // Type of optimization goal: minimize
                new NonNegativeConstraint(true) // The decision variables must be non-negative
        );

        // Output the solution
        double[] solutionPoint = solution.getPoint();
        System.out.println("Solution: ");
        for (double v : solutionPoint) {
            System.out.println(v);
        }
    }
}

The objective function for the optimization problem is defined as the minimization of the \( L_1 \) norm of the difference between the actual allocation of hedge sensitivities and the product of the ideal hedge allocation ratio for SA with the total aggregate hedge sensitivities. Mathematically, this can be expressed as:

$$
\text{minimize} \quad \left\| \mathbf{H}^T \mathbf{x} - r \cdot S \right\|_1
$$

where:

- $\mathbf{H}$ is the hedgeSensitivityArray, a column vector of hedge sensitivities.
- $\mathbf{H}^T$ is the transpose of \( \mathbf{H} \), turning it into a row vector.
- $\mathbf{H}\mathbf{x}$ is the vector of decision variables where each element is binary (either 0 or 1), indicating the allocation of a hedge to SA.
- $\mathbf{r}$ represents the idealHedgeAllocationRatioForSA, which is a scalar constant.
- $\mathbf{s}$ is the totalAggregateHedgesSensitivity, the sum of all elements in \( \mathbf{H} \).
- $\left\| \right\|$ denotes the $L_1$ norm, summing the absolute values of the elements in the vector.

The goal of the optimization is to find a vector $\mathbf{x}$ that minimizes this objective function subject to the given constraints.



import com.google.ortools.Loader;
import com.google.ortools.linearsolver.MPConstraint;
import com.google.ortools.linearsolver.MPObjective;
import com.google.ortools.linearsolver.MPSolver;
import com.google.ortools.linearsolver.MPVariable;

import java.util.Arrays;
import java.util.Random;
import java.util.stream.DoubleStream;

public class Main {

    public static void main(String[] args) {
        long startTime = System.currentTimeMillis();
        Loader.loadNativeLibraries();
        // Create the solver
        MPSolver solver = new MPSolver(

                "HedgeAllocationOptimization",
                MPSolver.OptimizationProblemType.CBC_MIXED_INTEGER_PROGRAMMING);
        double[] hedgeSensitivityArray = DoubleStream.generate(() -> new Random().nextDouble() * 1000000).limit(1000).toArray();
        // Example hedge sensitivity array H
        System.out.println(Arrays.toString(hedgeSensitivityArray));
        double hedgeSensitivityTotal = 0;
        for (int i = 0; i < hedgeSensitivityArray.length; i++) {
            hedgeSensitivityTotal += hedgeSensitivityArray[i];
        }
        double idealRatio = 0.75;

        // Create binary decision variables x
        MPVariable[] x = new MPVariable[hedgeSensitivityArray.length];
        for (int i = 0; i < hedgeSensitivityArray.length; i++) {
            x[i] = solver.makeIntVar(0, 1, "x" + i);
        }
//        MPVariable[] absDiff = new MPVariable[hedgeSensitivityArray.length];
        // Create auxiliary variables to represent the absolute value of the total difference

        MPVariable absDiff = solver.makeNumVar(0, Double.POSITIVE_INFINITY, "AbsDiff");

        // Define the objective function to minimize the total absolute difference
        MPObjective objective = solver.objective();
        objective.setCoefficient(absDiff, 1);
        objective.setMinimization();

        // Sum the differences
        double idealTotal = idealRatio*hedgeSensitivityTotal;
        MPConstraint positiveConstraint = solver.makeConstraint(Double.NEGATIVE_INFINITY, idealTotal);
        MPConstraint negativeConstraint = solver.makeConstraint(idealTotal, Double.POSITIVE_INFINITY);

        for (int i = 0; i < hedgeSensitivityArray.length; i++) {
            positiveConstraint.setCoefficient(x[i], hedgeSensitivityArray[i]);
            negativeConstraint.setCoefficient(x[i], hedgeSensitivityArray[i]);
        }
        positiveConstraint.setCoefficient(absDiff, -1);
        negativeConstraint.setCoefficient(absDiff,1);


        // Solve the problem
        final MPSolver.ResultStatus resultStatus = solver.solve();
        long endTime = System.currentTimeMillis();
        long timeTaken = endTime - startTime;
        System.out.println("Time taken: " + timeTaken + " milliseconds.");
        // Check if an optimal solution has been found
        if (resultStatus == MPSolver.ResultStatus.OPTIMAL) {
            System.out.println("Optimal solution found!");
            System.out.println("IdealTotalRatio = " + 0.75);
            // Output the solution
            double actualTotal = 0;
            for (int i=0; i<x.length; ++i) {
                actualTotal += x[i].solutionValue() * hedgeSensitivityArray[i];
            }
            System.out.println("ActualTotalRatio = " + actualTotal/idealTotal);
        } else {
            System.out.println("The problem does not have an optimal solution.");
        }
    }
}
