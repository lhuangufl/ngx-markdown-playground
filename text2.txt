// =====================================================================
// 1. Define Local Inner Class (Contains its own helpers)
// =====================================================================
class Trade {
    final String AggLevel;
    final String AggLevelValue;
    final String Regime;
    final String EntityId;
    final String RiskBucket;
    final String RiskClass;
    final String Family;
    final String RiskFactorName;
    final double WeightedSensitivity;

    double sumTermMed = 0.0;
    double sumTermLow = 0.0;
    double sumTermHigh = 0.0;

    Trade(Row r) {
        this.AggLevel = sStr(r.getAs("AGGREGATION_LEVEL"));
        this.AggLevelValue = sStr(r.getAs("AGGREGATION_LEVEL_VALUE"));
        this.Regime = sStr(r.getAs("REGIME"));
        this.EntityId = sStr(r.getAs("REPORTING_ENTITY_COPER_ID"));
        this.RiskBucket = sStr(r.getAs("RISK_BUCKET"));
        this.RiskClass = sStr(r.getAs("RISK_CLASS"));
        this.Family = sStr(r.getAs("RISK_FACTOR_SCENARIO_FAMILY"));
        this.RiskFactorName = sStr(r.getAs("RISK_FACTOR_NAME"));
        this.WeightedSensitivity = pDbl(r.getAs("WEIGHTED_SENSITIVITY"));
    }

    // Grouping Key for Matrix logic
    String getBucketKey() {
        return AggLevel + "|" + AggLevelValue + "|" + Regime + "|" + 
               EntityId + "|" + RiskBucket + "|" + RiskClass + "|" + Family;
    }

    // Static-like helpers inside the local class to ensure scope visibility
    private String sStr(Object val) {
        return val == null ? "" : String.valueOf(val);
    }

    private double pDbl(Object val) {
        if (val == null) return 0.0;
        if (val instanceof Number) return ((Number) val).doubleValue();
        try { return Double.parseDouble(val.toString()); } catch (Exception e) { return 0.0; }
    }
}

// Helper for building correlation keys (effectively final lambda)
// This handles the 6-parameter key construction
java.util.function.BiFunction<String, String, String> buildKey = (n1, n2) -> n1 + "||" + n2; 
// Note: For simplicity and to avoid the "cannot find symbol" for custom interfaces, 
// we'll combine the constant prefix logic in the loop.

final double PSI = 1.0; 

// =====================================================================
// 2. Data Ingestion & Correlation Map Building
// =====================================================================
Dataset<Row> sensDs = dsMap.get("SBM_DELTA_VEGA_SENSITIVITIES");
Dataset<Row> corrDs = dsMap.get("CORR_DATA");

if (sensDs == null || corrDs == null) throw new RuntimeException("Required datasets missing");

// Map Key: "Regime|Class|Bucket|Family|Name1|Name2"
Map<String, double[]> correlationMap = new HashMap<>();
List<Row> corrRows = corrDs.collectAsList();

for (Row r : corrRows) {
    // Using a temporary instance to access helper methods if needed, 
    // or just using String.valueOf directly for the Map building phase.
    String regime = String.valueOf(r.getAs("REGIME"));
    String rClass = String.valueOf(r.getAs("RISK_CLASS"));
    String bucket = String.valueOf(r.getAs("RISK_BUCKET"));
    String family = String.valueOf(r.getAs("RISK_FACTOR_SCENARIO_FAMILY"));
    String n1 = String.valueOf(r.getAs("RISK_FACTOR_NAME_1"));
    String n2 = String.valueOf(r.getAs("RISK_FACTOR_NAME_2"));
    
    String prefix = regime + "|" + rClass + "|" + bucket + "|" + family + "|";
    
    double low = (r.getAs("CORRELATION_LOW") instanceof Number) ? ((Number)r.getAs("CORRELATION_LOW")).doubleValue() : 0.0;
    double med = (r.getAs("CORRELATION_MEDIUM") instanceof Number) ? ((Number)r.getAs("CORRELATION_MEDIUM")).doubleValue() : 0.0;
    double high = (r.getAs("CORRELATION_HIGH") instanceof Number) ? ((Number)r.getAs("CORRELATION_HIGH")).doubleValue() : 0.0;
    
    double[] vals = new double[]{low, med, high};

    correlationMap.put(prefix + n1 + "||" + n2, vals);
    if (!n1.equals(n2)) {
        correlationMap.put(prefix + n2 + "||" + n1, vals);
    }
}

// =====================================================================
// 3. Calculation Logic
// =====================================================================
List<Row> sensRows = sensDs.collectAsList();
List<Trade> allTrades = new ArrayList<>(sensRows.size());
for (Row r : sensRows) {
    allTrades.add(new Trade(r));
}

Map<String, List<Trade>> bucketGroups = allTrades.stream()
    .collect(Collectors.groupingBy(Trade::getBucketKey));

bucketGroups.values().parallelStream().forEach(groupTrades -> {
    Trade[] nodes = groupTrades.toArray(new Trade[0]);
    int N = nodes.length;

    for (int i = 0; i < N; i++) {
        Trade t1 = nodes[i];
        String prefix = t1.Regime + "|" + t1.RiskClass + "|" + t1.RiskBucket + "|" + t1.Family + "|";

        for (int j = 0; j < N; j++) {
            Trade t2 = nodes[j];

            String key = prefix + t1.RiskFactorName + "||" + t2.RiskFactorName;
            double[] corrs = correlationMap.get(key);
            
            double rLow = 0.0, rMed = 0.0, rHigh = 0.0;
            if (corrs != null) {
                rLow = corrs[0]; rMed = corrs[1]; rHigh = corrs[2];
            } else if (t1.RiskFactorName.equals(t2.RiskFactorName)) {
                rLow = 1.0; rMed = 1.0; rHigh = 1.0;
            }

            double base = PSI * t1.WeightedSensitivity * t2.WeightedSensitivity;
            t1.sumTermLow  += (rLow * base);
            t1.sumTermMed  += (rMed * base);
            t1.sumTermHigh += (rHigh * base);
        }
    }
});

// =====================================================================
// 4. Result Packaging
// =====================================================================
List<Row> outputRows = new ArrayList<>();
for (Trade t : allTrades) {
    outputRows.add(RowFactory.create(
        t.AggLevel, t.AggLevelValue, t.Regime, t.EntityId, t.RiskBucket, 
        t.RiskClass, t.Family, t.RiskFactorName, 
        t.sumTermMed, t.sumTermLow, t.sumTermHigh, t.WeightedSensitivity
    ));
}

StructType schema = DataTypes.createStructType(new StructField[]{
    DataTypes.createStructField("AGGREGATION_LEVEL", DataTypes.StringType, false),
    DataTypes.createStructField("AGGREGATION_LEVEL_VALUE", DataTypes.StringType, false),
    DataTypes.createStructField("REGIME", DataTypes.StringType, false),
    DataTypes.createStructField("REPORTING_ENTITY_COPER_ID", DataTypes.StringType, false),
    DataTypes.createStructField("RISK_BUCKET", DataTypes.StringType, false),
    DataTypes.createStructField("RISK_CLASS", DataTypes.StringType, false),
    DataTypes.createStructField("RISK_FACTOR_SCENARIO_FAMILY", DataTypes.StringType, false),
    DataTypes.createStructField("RISK_FACTOR_NAME", DataTypes.StringType, false),
    DataTypes.createStructField("TERM_OFF_DIAGONAL_MEDIUM", DataTypes.DoubleType, false),
    DataTypes.createStructField("TERM_OFF_DIAGONAL_LOW", DataTypes.DoubleType, false),
    DataTypes.createStructField("TERM_OFF_DIAGONAL_HIGH", DataTypes.DoubleType, false),
    DataTypes.createStructField("WEIGHTED_SENSITIVITY_K", DataTypes.DoubleType, false)
});

return spark.createDataFrame(outputRows, schema);
